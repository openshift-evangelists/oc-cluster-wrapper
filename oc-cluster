#!/bin/bash

OC_CLUSTER_PUBLIC_HOSTNAME=${OC_CLUSTER_PUBLIC_HOSTNAME:-127.0.0.1}
OC_CLUSTER_ROUTING_SUFFIX=${OC_CLUSTER_ROUTING_SUFFIX}
OPENSHIFT_HOME_DIR=${OPENSHIFT_HOME:-$HOME/.oc}
OPENSHIFT_CACHE_DIR=${OPENSHIFT_CACHE:-/var/lib/origin}

function up {
  local _profile="$1"
  
  # Test that there is not a running cluster already
  status &> /devn/null && error_exit "There is a cluster already running. You can not run 2 cluster at the same time"

  if [ "$_profile" == "" ] || [[ $_profile == -* ]]
  then
     echo "Using default profile"
     _profile="default"
  else
     shift # Remove profile name
  fi

  # TODO: If the cluster is already created, do not provision stuff
  if [ ! -d "$OPENSHIFT_HOME_DIR/profiles/$_profile" ] || [ ! -e "$OPENSHIFT_HOME_DIR/profiles/$_profile/run" ] 
  then 
    echo "[INFO] Running a new cluster"
    # This is where oc cluster stores it's data
    local OPENSHIFT_HOST_DATA_DIR=$OPENSHIFT_HOME_DIR/profiles/$_profile/data
    local OPENSHIFT_HOST_CONFIG_DIR=$OPENSHIFT_HOME_DIR/profiles/$_profile/config
    local OPENSHIFT_HOST_VOLUMES_DIR=$OPENSHIFT_HOME_DIR/profiles/$_profile/volumes

    mkdir -p $OPENSHIFT_HOST_CONFIG_DIR
    mkdir -p $OPENSHIFT_HOST_DATA_DIR
    mkdir -p $OPENSHIFT_HOST_VOLUMES_DIR

    echo "oc cluster up --public-hostname '$OC_CLUSTER_PUBLIC_HOSTNAME' \
                --host-data-dir '$OPENSHIFT_HOST_DATA_DIR' \
                --host-config-dir '$OPENSHIFT_HOST_CONFIG_DIR' \
                --routing-suffix '$OC_CLUSTER_ROUTING_SUFFIX' \
                --use-existing-config \
                $@" > $OPENSHIFT_HOME_DIR/profiles/$_profile/run

    echo "$(<$OPENSHIFT_HOME_DIR/profiles/$_profile/run)"

    
    oc cluster up --public-hostname $OC_CLUSTER_PUBLIC_HOSTNAME \
                --host-data-dir $OPENSHIFT_HOST_DATA_DIR \
                --host-config-dir $OPENSHIFT_HOST_CONFIG_DIR \
                --routing-suffix "$OC_CLUSTER_ROUTING_SUFFIX" \
                --use-existing-config \
                "$@"
    
    status &> /dev/null  || cleanupClusterAndExit $__profile
    # Create the profile markfile
    echo "${_profile}" > $OPENSHIFT_HOME_DIR/active_profile

    echo "[INFO] Cluster created succesfully"
    #Add developer as sudoer
    oc adm policy add-cluster-role-to-group sudoer system:authenticated \
         --config="${OPENSHIFT_HOST_CONFIG_DIR}/master/admin.kubeconfig" \
         --context="default/127-0-0-1:8443/system:admin"

    echo "Any user is sudoer. They can execute commands with '--as=system:admin'"
    # Create user admin that can log into the console
    oc adm policy add-cluster-role-to-user cluster-admin admin --as=system:admin
  else
    echo "[INFO] Running a previously created cluster"
    # Just start the cluster 
    echo "$(<$OPENSHIFT_HOME_DIR/profiles/$_profile/run)"
    . $OPENSHIFT_HOME_DIR/profiles/$_profile/run "$@"
  fi
}

function cleanupClusterAndExit() {
  rm -rf $OPENSHIFT_HOME_DIR/profiles/$1
  error_exit "[ERROR] There's been an error creating the cluster, the profile will be removed"
}

function down {

  status &> /dev/null || return
  echo "Bringing the cluster down"
  oc cluster down
  rm -f $OPENSHIFT_HOME_DIR/active_profile
}

#
# Args:
#  $1: [-s] silent
function status {
  [[ "$(docker ps -f name=origin -q)" == "" ]] && echo "no cluster running" && return 1
  echo "oc cluster running. Current profile <$([ -f $OPENSHIFT_HOME_DIR/active_profile ] && cat $OPENSHIFT_HOME_DIR/active_profile || echo 'unknown')>"
  return 0
}

# If the cluster is up, it will bring it down and destroy active_profile
# Otherwise will ask for profile 
function destroy {
  local _profile=$1
  local _active_profile=$([ -f $OPENSHIFT_HOME_DIR/active_profile ] && cat $OPENSHIFT_HOME_DIR/active_profile || echo '')

  if [ $# -lt 1 ] && [ "${_active_profile}" == "" ]
  then
    echo "You need to specify a profile, or have a running cluster"
    exit 1
  fi
  [ "$_profile" == "" ] && _profile=$_active_profile

  if [ ! -d "$OPENSHIFT_HOME_DIR/profiles/$_profile" ]
  then
    echo "There is no profile named $_profile"
    exit 1
  fi

  if [ "$_profile" != "" ]
  then
     read -p "Are you sure you want to destroy cluster with profile <$_profile> (y/n)? " -n 1 -r
     echo    # move to a new line
     if [[ $REPLY =~ ^[Yy]$ ]]
     then
        # do dangerous stuff
        echo "Removing profile $_profile"
        if [ "$_active_profile" == "$_profile" ]
        then
           down
        fi
        echo "Removing $OPENSHIFT_HOME_DIR/profiles/$_profile"
        rm -rf $OPENSHIFT_HOME_DIR/profiles/$_profile
        # TODO: Remove the images
     fi
  fi
}

function list {
  echo "Profiles:"
  for i in `ls $OPENSHIFT_HOME_DIR/profiles`
  do
     echo "- $i"
  done
}

function error_exit() {
  echo -e "$@"
	exit 1
}

function deploy-nexus {
  status &> /dev/null  || error_exit "There's no cluster running"
  oc adm new-project ci --as=system:admin
  create-shared-volume 'ci/nexus-data'
  oc create -f https://raw.githubusercontent.com/openshift-evangelists/vagrant-origin/master/utils/nexus/nexus.yaml -n ci --as=system:admin
  oc adm policy add-role-to-user admin $(oc whoami) --as=system:admin -n ci
  echo "Project ci has been created and shared with you. It has a nexus instance that has shared storage with other clusters"
}

function ssh {
  echo "Going into the Origin Container"
  docker exec -it origin /bin/bash
}

function console {
  echo "https://127.0.0.1:8443/console"
}

function create-volume {
  local __volume=$1
  local __size='10Gi'
  local __path=''

  [ $# -lt 1 ] && echo "volumename is required" && exit 1

  __profile=$(cat $OPENSHIFT_HOME_DIR/active_profile)
  if [ ! -z "$2" ]; then
    __size=$2
  fi
  if [ -z "$3" ]; then
    __path=$OPENSHIFT_HOME_DIR/profiles/${__profile}/volumes/${__volume}
  else
    __path=$3
  fi

  mkdir -p $__path

cat <<-EOF > /tmp/pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${__volume}
spec:
  capacity:
    storage: ${__size}
  accessModes:
    - ReadWriteOnce
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: ${__path}
EOF

oc create -f /tmp/pv.yaml --as=system:admin
rm /tmp/pv.yaml

echo "Volume created in ${__path}"
}

#
# Args:
#  $1: volumeName. Format (project/volumeName). A prebounded claim will be created to bound to a claim with Name volume in project 
#  $2: size (10Gi, 512Mi) (optional)
#  $3: Path for the volume (optional)
function create-shared-volume {
  [ $# -lt 1 ] && echo "volumename is required. This should take the form of <project>/<name> so the volume will be prebounded to the claim with same name in the specified project" && exit 1

  local __projectclaim=$1
  arrIN=(${__projectclaim//\// })
  [ ${#arrIN[@]} -lt 2 ] && echo "volumename format is not valid.  This should take the form of <project>/<name> so the volume will be prebounded to the claim with same name in the specified project" && exit 1
  
  local __volume=${arrIN[1]}
  local __project=${arrIN[0]}
  local __size='10Gi'
  local __path=''

  if [ ! -z "$2" ]; then
    __size=$2
  fi
  if [ -z "$3" ]; then
    __path=$OPENSHIFT_HOME_DIR/volumes/${__volume}
  else
    __path=$3
  fi

  mkdir -p $__path
  
  # TODO: Check if volume exists

cat <<-EOF > /tmp/pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${__volume}
spec:
  capacity:
    storage: ${__size}
  accessModes:
    - ReadWriteOnce
    - ReadWriteMany
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    namespace: ${__project}
    name: ${__volume}
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: ${__path}
EOF

oc create -f /tmp/pv.yaml --as=system:admin
rm /tmp/pv.yaml

echo "Volume created in ${__path}"
}

function help {
        echo "Valid commands:"
        echo "oc-cluster up [profile] [OPTIONS]"
        echo "oc-cluster down"
        echo "oc-cluster destroy [profile]"
        echo "oc-cluster list"
        echo "oc-cluster status"
        echo "oc-cluster ssh"
        echo "oc-cluster console"
        echo "oc-cluster create-volume volumeName [size|10Gi] [path|$HOME/.oc/profiles/<profile>/volumes/<volumeName>]"
        echo "oc-cluster create-shared-volume project/volumeName [size|10Gi] [path|$HOME/.oc/volumes/<volumeName>]"
        echo "oc-cluster deploy-nexus"
}

# Use -gt 1 to consume two arguments per pass in the loop (e.g. each
# argument has a corresponding value to go with it).
# Use -gt 0 to consume one or more arguments per pass in the loop (e.g.
# some arguments don't have a corresponding value to go with it such
# as in the --default example).
if [[ $# -gt 0 ]]
then
   key="$1"
   case $key in
      up)
        shift # past argument
        up "$@"
        ;;
      down)
        shift # past argument
        down "$@"
        ;;
      destroy)
        shift # past argument
        destroy "$@"
        ;;
      list)
        list
        ;;
      status)
        status
        ;;
      ssh)
        shift
        ssh "$@"
        ;;
      create-volume)
        shift
        create-volume "$@"
        ;;
      create-shared-volume)
        shift
        create-shared-volume "$@"
        ;;
      deploy-nexus)
        shift
        deploy-nexus "$@"
        ;;
      console)
        shift
        console "$@"
        ;;
      -h|help)
        help        
        ;;
      *)
        # unknown option
        echo "Unknown option. Show help"
        help        
        ;;
   esac
else
   help
fi


